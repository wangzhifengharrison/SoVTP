# Visual and Textual Prompts in VLLMs for Enhancing Emotion Recognition

**Authors:** Zhifeng Wang, Student Member, IEEE, Qixuan Zhang, Peter Zhang, Wenjia Niu, Kaihao Zhang, Ramesh Sankaranarayana, Sabrina Caldwell, Tom Gedeon, Senior Member, IEEE

**Abstract:** Vision Large Language Models (VLLMs) exhibit promising potential for multi-modal understanding, yet their application to video-based emotion recognition remains limited by insufficient spatial and contextual awareness. Traditional approaches, which prioritize isolated facial features, often neglect critical non-verbal cues such as body language, environmental context, and social interactions, leading to reduced robustness in real-world scenarios. To address this gap, we propose Set- of-Vision-Text Prompting (SoVTP), a novel framework that enhances zero-shot emotion recognition by integrating spatial annotations (e.g., bounding boxes, facial landmarks), physio- logical signals (facial action units), and contextual cues (body posture, scene dynamics, others‚Äô emotions) into a unified prompt- ing strategy. SoVTP preserves holistic scene information while enabling fine-grained analysis of facial muscle movements and interpersonal dynamics. Extensive experiments show that SoVTP achieves substantial improvements over existing visual prompting methods, demonstrating its effectiveness in enhancing VLLMs‚Äô video emotion recognition capabilities.
---

## üìñ Overview

This repository accompanies our paper **‚ÄúVisual and Textual Prompts in VLLMs for Enhancing Emotion Recognition‚Äù**, in which we introduce **Set-of-Vision-Text Prompting (SoVTP)**, a zero-shot framework that significantly boosts video-based emotion recognition by integrating:

- **Spatial annotations** (bounding boxes, facial landmarks, Action Units)  
- **Physiological cues** (facial muscle movements via Action Units)  
- **Contextual information** (scene layout, objects, activities)  
- **Social signals** (body posture, gestures, others‚Äô emotions)


